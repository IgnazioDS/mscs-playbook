# Intelligent Agents and Rationality

## Overview
Intelligent agents perceive their environment and act to maximize expected
performance under uncertainty.

## Why it matters
Agent abstractions drive AI system design and clarify how goals, observations,
and actions interact.

## Key ideas
- Agents map percept histories to actions
- Rationality maximizes expected utility
- Environments differ by observability and dynamics
- Performance measures define success

## Practical workflow
- Define goals and reward structure
- Specify sensors, actions, and environment assumptions
- Choose agent type (reflex, model-based, goal, utility)
- Validate behavior with simulation scenarios

## Failure modes
- Misaligned objectives or reward hacking
- Partial observability causing risky actions
- Overfitting to narrow environments
- Incorrect assumptions about dynamics

## Checklist
- Document performance metrics and constraints
- Validate on diverse scenarios and edge cases
- Add safety constraints and overrides
- Monitor agent behavior for drift

## References
- Russell & Norvig, Artificial Intelligence: A Modern Approach (AIMA)
- Agent taxonomy overview â€” https://aima.cs.berkeley.edu/
