# Safety, Security, and Misuse

## What it is
Protecting systems from accidental harm, adversarial behavior, and abuse.

## Why it matters
ML systems can be exploited or cause harm at scale when safety is ignored.

## Core concepts
- Threat modeling and abuse cases
- Adversarial inputs and prompt injection
- Safety guardrails and monitoring

## Common failure modes
- No red-team testing prior to launch
- Shipping without abuse monitoring
- Weak incident response preparation

## Engineering checklist
- Define misuse scenarios and mitigations
- Test for prompt injection or data exfiltration
- Establish incident response triggers

## References
- OWASP ML Security Top 10
- NIST AI RMF Safety guidance
