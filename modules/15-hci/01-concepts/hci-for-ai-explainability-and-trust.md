# HCI for AI: Explainability and Trust

## Overview
HCI for AI focuses on helping users understand, calibrate, and trust AI
capabilities and limitations.

## Key Concepts
- Mental model alignment for AI behavior.
- Explanations that are actionable and truthful.
- Confidence cues and uncertainty communication.
- Human-in-the-loop control and override.

## Practical Notes
- Use layered explanations: summary, details, provenance.
- Distinguish between system confidence and correctness.
- Design for safe failure and graceful fallback.

## Common Pitfalls
- Overconfident UI that implies certainty.
- Explanations that are too technical or too vague.
- Lack of clear handoff to human control.

## Checklist
- Known limitations are visible in the UI.
- Users can verify and correct AI outputs.
- Feedback mechanisms are simple and accessible.

## Further Reading
- Human-AI interaction guidelines
- Uncertainty visualization
- Trust calibration in decision support systems
